{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evolution-strategies\n",
    "\n",
    "Copyright (c) 2019 Patrick Deubel\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in\n",
    "all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "THE SOFTWARE.\n",
    "\n",
    "evolution-strategies includes:\n",
    "\n",
    "evolution-strategies-starter\n",
    "Copyright (c) 2016 OpenAI (http://openai.com)\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in\n",
    "all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using evolution strategies to train Roboschool Environments\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This Jupyter Notebook is based on the [paper](https://arxiv.org/abs/1703.03864), [blog article](https://openai.com/blog/evolution-strategies/) and [implementation](https://github.com/openai/evolution-strategies-starter) of OpenAI on the topic of using an evolution strategy algorithm for a typical reinforcement learning task. \n",
    "\n",
    "My implementation summarizes their implementation, by simplifying, refactoring and organizing the code into this Jupyter notebook which can be used to test the algorithm. One can tweak the hyperparameters, change the environment which shall be trained or even expand the implementation to support for example Atari environments.\n",
    "\n",
    "I recommend reading the paper or at least the article before trying out the notebook. Also depending on the environment the training can be very computationally intense (for example training the Humanoid), so if you want to try out the harder ones I recommend using a highly parallelizable machine, i.e. a machine with a high number of cores/threads which can use multiple processes simultaneously.\n",
    "\n",
    "## Algorithm overview\n",
    "\n",
    "This section gives a brief overview over the algorithm. First of all we need to define what this implementation is going to do. The Roboschool is a group of environments in the [OpenAi Gym](https://gym.openai.com/), a program to test the behavior of machine learning algorithms on _real world_ problems. In our case, we want to train different robotic environments using an evolutionary algorithm which belongs to the class of natural evolution strategies. We therefore define a neural net with a configurable number of hidden layers, where the input dimension equals the observation space of the environment and the dimension of the output layer equals the dimension of the action space of the environment. This neural net is also called policy or in this implementation also referred to as a model. Therefore we train our policy to output the best possible action sequence given an observation sequence. Now, how do we train this policy? Training an evolutionary strategy consists of a cycle which is repeated over and over. First, an initial weight vector is randomly generated. In our context this weight vector is equal to the weights of our policy. Then we perturb the vector with gaussian noise. The number of perturbations is called the population size. What we now have is a population of slightly different weight vectors compared with the weight vector we started. Each one of these vectors will then be evaluated by first updating our policy with the weights and then run the environment using the policy. When this is done for the whole population, we calculate a gradient ascent step in the direction of steepest ascent. In our case, where we are dealing with natural evolution strategies, we calculate the step with the natural gradient. This is done by approximating this gradient using Monte Carlo estimates.\n",
    "\n",
    "So lets say we have our initial weight vector $\\theta$, a population size $n$, random perturbations $\\epsilon_i$, $0 \\leq i \\leq n$, learning rate $\\alpha$, noise standard deviation $\\sigma$ and a fitness Function $F(\\cdot)$. We then calculate the resulting weight vector like this:\n",
    "$\\theta_{t+1} = \\theta_{t} + \\alpha \\frac{1}{n \\sigma} \\sum \\limits_{i=0}^n F(\\theta_{t} + \\epsilon_i)$\n",
    "\n",
    "\n",
    "This gives us the weight vector for the next cycle which we will then, again, perturb a number of times (depending on the population size). A cycle in the context of evolutionary strategies is called a generation.\n",
    "\n",
    "One might ask himself now what this fitness function is in the context of robotic simulations. When initializing such an environment one can call the `step` function on the environment with an array in the shape of the action space (in our case this would be the output of the policy). The environment then evaluates the provided action based on the current observation and other parameters in the environment and outputs a reward. This is done for either a fixed number of timesteps (some environments have a maximum of timesteps defined) or stops, when the action resulted in a state where the environment is `done`, for example when the `Humanoid` environment falls over and touches the surface. The rewards get summed up for every timestep which forms the reward for one action.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Before starting any computation we need to configure the training and define some methods and objects we will use later on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Note that TensorFlow does not get imported here. We will only import it inside of a function which runs in another process. This is due to the fact that when importing TensorFlow a session is created in the background which will interefere with our models which we run in subprocesses. When importing the package only inside a function and then running these functions inside of subprocesses, every process has its own TensorFlow session and they therefore don't interfere with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import errno\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "import ctypes\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "\n",
    "import gym, roboschool\n",
    "\n",
    "import pybullet, pybullet_envs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory for storing the training\n",
    "\n",
    "For evaluating the trained data we need to define a directory where we want to store the trained policies, as well as the log file to record the results of every generation.\n",
    "\n",
    "Depending on your disk space you may not want to save every model, but for an indepth evaluation this is necessary. During training there will be so called _evaluation runs_ which will not add noise but test the currently trained policy to give insight on training. But since it relies on probability the number of evaluation runs will not be equal through generations. An additional Jupyter Notebook with the prefix **-visualization** can be used after training to load all saved weight files and evaluate them a given number of times.\n",
    "\n",
    "If you want to change the location change the variable `main_directory` to a directory where the user which runs this notebook has write permissions. If it does not exist the program will create it. The default location is a `training_runs` folder which is created in the working directory.\n",
    "\n",
    "When starting the master a subfolder is created inside `main_directory` where the the current progress of a training is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "main_directory = \"/home/jovyan/work/evolution-strategies/training_runs/\".format(os.getpid())\n",
    "try:\n",
    "    mkdir_p(main_directory)\n",
    "except PermissionError:\n",
    "    print(\"The user running this notebook has no permission to create this folder. Please provide a path to a folder\"\n",
    "         + \" with write permissions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Configuration, Task and Result Classes\n",
    "\n",
    "Using `namedtuple` from the `collections` package from python allows us to quickly create small classes with different attributes, which is ideal for quickly accessing different attributes during training as well as saving the configurations to a file.\n",
    "\n",
    "Each attribute will be explained in a bit, where objects of these classes are created and their parameters are set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Config = namedtuple('Config', [\n",
    "    'env_id',\n",
    "    'population_size',\n",
    "    'timesteps_per_gen',\n",
    "    'num_workers',\n",
    "    'learning_rate',\n",
    "    'noise_stdev',\n",
    "    'snapshot_freq',\n",
    "    'return_proc_mode',\n",
    "    'calc_obstat_prob',\n",
    "    'l2coeff',\n",
    "    'eval_prob'\n",
    "])\n",
    "\n",
    "Optimizations = namedtuple('Optimizations', [\n",
    "    'mirrored_sampling',\n",
    "    'fitness_shaping',\n",
    "    'weight_decay',\n",
    "    'discretize_actions',\n",
    "    'gradient_optimizer',\n",
    "    'observation_normalization',\n",
    "    'divide_by_stdev'\n",
    "])\n",
    "\n",
    "ModelStructure = namedtuple('ModelStructure', [\n",
    "    'ac_noise_std',\n",
    "    'ac_bins',\n",
    "    'hidden_dims',\n",
    "    'nonlin_type',\n",
    "    'optimizer',\n",
    "    'optimizer_args'\n",
    "])\n",
    "\n",
    "Task = namedtuple('Task', [\n",
    "    'theta', 'ob_mean', 'ob_std', 'task_id'])\n",
    "\n",
    "Result = namedtuple('Result', [\n",
    "    'noise_inds','returns', 'signreturns', 'lengths',\n",
    "    'eval_return', 'eval_length',\n",
    "    'ob_sum', 'ob_sumsq', 'ob_count',\n",
    "    'task_id',\n",
    "    'times_predict'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "#### Optimizations object\n",
    "\n",
    "First we start with the optimizations for the training, since other parameters are only used when the respective optimization is activated.\n",
    "\n",
    "All values can only be either `True` or `False`. The term _activated_ means the value is set to `True` in this context.\n",
    "\n",
    "When `mirrored_sampling` is activated, sampled noise gets used twice: One time it will get added to the parameter vector and the result gets evaluated and the other time it gets subtracted from the parameter vector and the result will be evaluated.\n",
    "\n",
    "`fitness_shaping` processes the rewards by applying a rank transformation.\n",
    "\n",
    "`weight_decay` slighty changes the parameter vector.\n",
    "\n",
    "`discretize_actions` can be used to bin the actions. This means that you can provide a number of uniformely shaped bins in which the output of the model will be put. For some environments this can encourage exploration behavior.\n",
    "\n",
    "`gradient_optimizer` will use a gradient optimizer for the computed gradient, for example the `Adam` optimizer.\n",
    "\n",
    "`observation_normalization` When turned on, before an observation gets feeded into the neural network it will be subtracted by the observation mean and divided with the observation standard deviation. The observation mean and standard deviation get constantly updated on training based on the configured probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "optimizations = Optimizations(\n",
    "    mirrored_sampling=True,\n",
    "    fitness_shaping=True,\n",
    "    weight_decay=True,\n",
    "    discretize_actions=True,\n",
    "    gradient_optimizer=True,\n",
    "    observation_normalization=True,\n",
    "    divide_by_stdev=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Config object\n",
    "\n",
    "The config object will serve us as a general configuration for the training.\n",
    "\n",
    "First of all it defines the `env_id` which has to be a valid ID for a `Roboschool` environment, for example `RoboschoolAnt-v1`. A complete list can be found [here](https://github.com/openai/roboschool/blob/master/roboschool/__init__.py).\n",
    "\n",
    "`population_size` defines the number of perturbations per generation.\n",
    "\n",
    "`timesteps_per_gen` defines the minimum number of timesteps which shall be processed during a generation.\n",
    "\n",
    "`num_workers` defines the amount of parallel processes to be created during calculation and must be larger than 0. By default this value is the output of `os.cpu_count()` which allows the program to use the maximum amount of computational power in terms of the provided hardware.\n",
    "\n",
    "`learning_rate` defines how much the estimated gradient influences the next generation and must be larger than 0 for the training to work. If the gradient optimizer is activated this value is not used. Instead, `step_size` in the model structure is the corresponding value.\n",
    "\n",
    "`noise_stdev` is the standard devation for the noise and should be larger than 0. It cannot be equal to 0 since if it would be at some point there could then be a division by zero. Other than that it would not benefit training.\n",
    "\n",
    "`snapshot_freq` describes the frequency in which generations shall be saved to a `.h5` file. For example a snapshot frequency of 5 would save every fifth generation to a file. Setting it to 0 disables snapshotting.\n",
    "\n",
    "`return_proc_mode` translates to return processing mode and describes how the calculated rewards for a generation shall be processed. By default this is `centered_rank` which will calculate the ranks of the rewards. This option is only used when also activating the `fitness_shaping` optimization. One can choose between the three strings `RETURN_PROC_MODE_CR`, `RETURN_PROC_MODE_SIGN` and `RETURN_PROC_MODE_CR_SIGN`.\n",
    "\n",
    "`calc_obstat_prob` is the probability of saving the observations during a rollout (evaluating the fitness of a policy) and updating the observation mean and standard deviation. These values are used to normalize the input of a model which helps a neural network to generalize faster. The parameter is only used in combination with the `observation_normalization` optimization. Must be greater than 0 when using the optimization since otherwise it would waste performance while not normalizing.\n",
    "\n",
    "`l2coeff` is the coefficient which is used for weight decay to deform the parameter vector.\n",
    "\n",
    "`eval_prob` is the probability of inserting an evaluation run. This is useful for training to quickly monitor the reward mean, reward standard deviation and length mean of the current generation. The value must be greater or equal 0 (equal 0 turns of the evaluation runs).\n",
    "\n",
    "Below the configuration we create an environment with the configured ID and check if it is valid. If it is, `ob_space` and `ac_space` are created. They are used inside `create_model`, which we will look at in a bit, because they equal the\n",
    "input and output dimension of the model. So if you decide to change the configuration, they need to be changed as well. Therefore we define them here. Generally speaking as long as one does not rerun a cell, old values are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RETURN_PROC_MODE_CR = 'centered_rank'\n",
    "RETURN_PROC_MODE_SIGN = 'sign'\n",
    "RETURN_PROC_MODE_CR_SIGN = 'centered_sign_rank'\n",
    "\n",
    "config = Config(\n",
    "    env_id=\"RoboschoolAnt-v1\",\n",
    "    population_size=8,\n",
    "    timesteps_per_gen=10000,\n",
    "    num_workers=os.cpu_count(),\n",
    "    learning_rate=0.001,\n",
    "    noise_stdev=0.02,\n",
    "    snapshot_freq=1,\n",
    "    return_proc_mode=RETURN_PROC_MODE_CR,\n",
    "    calc_obstat_prob=0.01,\n",
    "    l2coeff=0.005,\n",
    "    eval_prob=0.003\n",
    ")\n",
    "\n",
    "try:\n",
    "    env = gym.make(config.env_id)\n",
    "except:\n",
    "    print(\"Please provide a valid environment ID for the OpenAI Gym. {} is not valid.\".format(config.env_id))\n",
    "\n",
    "# These are used inside create_model for the input and output dimensions\n",
    "ob_space = env.observation_space\n",
    "ac_space = env.action_space\n",
    "\n",
    "assert config.population_size > 0\n",
    "assert config.num_workers > 0\n",
    "assert config.learning_rate > 0\n",
    "assert config.noise_stdev != 0\n",
    "assert config.eval_prob >= 0\n",
    "\n",
    "if (config.return_proc_mode != RETURN_PROC_MODE_CR\n",
    "    and config.return_proc_mode != RETURN_PROC_MODE_SIGN\n",
    "    and config.return_proc_mode != RETURN_PROC_MODE_CR_SIGN):\n",
    "    \n",
    "    raise NotImplementedError\n",
    "    \n",
    "if optimizations.observation_normalization:\n",
    "    assert config.calc_obstat_prob > 0\n",
    "\n",
    "if optimizations.gradient_optimizer:\n",
    "    assert config.l2coeff > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ModelStructure object\n",
    "\n",
    "The ModelStructure object defines the overall structure of the neural network.\n",
    "\n",
    "`ac_noise_std` is the standard deviation for the noise which is added during training. Adding noise shall generalize the training. It must be greater than 0, or equal to 0 for no noise.\n",
    "\n",
    "When using the `discretize_actions` optimizations, `ac_bins` defines into how much uniformely spaced bins the actions shall be put. For example if the possible action values range from -1 to 1 and one defines 5 action bins the model will output values from $\\{-1, -0.5, 0, 0.5, 1\\}$. If you use the optimization the number of bins must be greater than 0.\n",
    "\n",
    "`hidden_dims` define the number of hidden layers and their dimensions. It must be a list of positive Integers.\n",
    "\n",
    "`nonlin_type` defines the activation function for the hidden layers. Can be `tanh`, `relu`, `lrelu` or `elu` for the hyperbolic tangent, rectified linear, leaky ReLU and the exponential linear. If something else is defined `tanh` will be picked.\n",
    "\n",
    "`optimizer` is only used when the `gradient_optimizer` optimization is turned on. It can be `adam` for the Adam optimizer or `sgd` for the SGD Optimizer. Defining anything other will result in an error.\n",
    "\n",
    "`optimizer_args` is only used when the `gradient_optimizer` optimization is turned on. This will be feeded into the constructor of the optimizer. For the Adam and SGD optimizer one must specify the `stepsize` but can also specify other optimizer specific attributes. Please check the constructor signature for the names. If you specify something else than stepsize be careful, this does not get checked for errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "OPTIMIZER_ADAM = 'adam'\n",
    "OPTIMIZER_SGD = 'sgd'\n",
    "\n",
    "model_structure = ModelStructure(\n",
    "    ac_noise_std=0.01,\n",
    "    ac_bins=5,\n",
    "    hidden_dims=[256, 256],\n",
    "    nonlin_type='tanh',\n",
    "    optimizer=OPTIMIZER_ADAM,\n",
    "    optimizer_args={\n",
    "        'stepsize': config.learning_rate\n",
    "    }\n",
    ")\n",
    "\n",
    "assert model_structure.ac_noise_std >= 0\n",
    "assert isinstance(model_structure.hidden_dims, list)\n",
    "assert all(hd >= 0 for hd in model_structure.hidden_dims)\n",
    "\n",
    "if optimizations.gradient_optimizer:\n",
    "    if model_structure.optimizer != OPTIMIZER_ADAM and model_structure.optimizer != OPTIMIZER_SGD:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    try:\n",
    "        stepsize = model_structure.optimizer_args['stepsize']\n",
    "        assert stepsize > 0\n",
    "    except KeyError:\n",
    "        print(\"Please provide the stepsize parameter.\")\n",
    "\n",
    "if optimizations.discretize_actions:\n",
    "    assert model_structure.ac_bins > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task class\n",
    "\n",
    "During training the master will enqueue a new Task object per generation. The workers will then take the latest task, compute it and push a result object on a queue. In the following table the attributes of a task object are explained in depth.\n",
    "\n",
    "| Attribute | Explanation |\n",
    "| :---------|:------------|\n",
    "| `theta`   | The one-dimensional parameter vector of this task, i.e. the current generation|\n",
    "| `ob_mean` | When observation normalization is used this is the current mean of the observed observation |\n",
    "| `ob_std`  | When observation normalization is used this is the current standard deviation of the observed observation|\n",
    "| `task_id` | The ID of this Task, which equals the generation number |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result class\n",
    "\n",
    "An object of the Result class will define a computed task by the workers. This can either be an evaluation task, where no noise gets added and the policy will simply be evaluated on the environment or a regular task. This means that the noise gets sampled, added (and subtracted when mirrored sampling is used) and evaluated. The following table gives a more detailed information on each attribute.\n",
    "\n",
    "| Attribute             | Explanation   |\n",
    "| :---------------------|:--------------|\n",
    "| `noise_inds`        | A numpy array with the indices of the used noise|\n",
    "| `returns`        | A numpy array with the rewards. When mirrored sampling is used this list is two dimensional| |`signreturns` | The sum of the signs of the rewards. When mirrored sampling is used this list is two dimensional| |`lengths` | A numpy array with the sum of the timesteps. When mirrored sampling is used this list is two dimensional|\n",
    "| `eval_return` | np.nan if this was not an evaluation task, otherwise a numpy array with the reward of the evaluation|\n",
    "| `eval_length`|np.nan if this was not an evaluation task, otherwise a numpy array with the timesteps of the evaluation| |`ob_sum` | If observation normalization is used this contains the sum of the tracked observations |\n",
    "| `ob_sumsq` | If observation normalization is used this contains the squared sum of the tracked observations |\n",
    "| `ob_count` | If observation normalization is used this contains the amount of tracked observations|\n",
    "| `task_id` | The ID of the task that has been calculated|\n",
    "| `times_predict` | A list of time measurements, where each value is the time how long a prediciton with the Keras model needs| "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the configuration\n",
    "\n",
    "When this method is called the specified configuration gets saved to `save_directory`, so when training is done one can reproduce the training with the exact parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def save_configuration(save_directory):\n",
    "    with open(os.path.join(save_directory, 'config.json'), 'w', encoding='utf-8') as f:\n",
    "        chained_dict = OrderedDict([\n",
    "            ('config', config._asdict()),\n",
    "            ('model_structure', model_structure._asdict()),\n",
    "            ('optimizations', optimizations._asdict())])\n",
    "\n",
    "        json.dump(chained_dict, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Function, Variable and Class definitions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Using Keras for the models\n",
    "\n",
    "The original implementation from OpenAI used chained TensorFlow operations to construct the model. This notebook however, uses Keras (which is integrated into TensorFlow) as a high-level API to construct `Model` objects. These objects are, in our case, chained layers which will represent our neural network.\n",
    "\n",
    "Also, note that all imports of TensorFlow need to be inside function definitions and these functions can only be called inside subprocesses. This is needed since importing TensorFlow automatically starts a background session which would be inherited to then started subprocesses. Therefore each worker would have the same TensorFlow session which would interfere with their respective models. Another noteworthy finding is that when creating Keras models in a loop there will be a memory leak when one does not clear the session. This will be adressed in the `run_worker` method.\n",
    "\n",
    "In the following cell the method `create_model` creates and returns a Keras model as defined with the configurations. It needs to have the `ob_space` and `ac_space` variable set to the observation space and action space of the used environment in training, because they define the input and output dimension.\n",
    "\n",
    "After adding an input layer the method will add the custom `ObservationNormalizationLayer` if the `observation_normalization` optimization is turned on. This layer uses the method parameters `ob_mean` and `ob_std` to normalize the input $o$ with this equation $\\frac{o - \\text{ob_mean}}{\\text{ob_std}}$ and clip the values to $[-5, 5]$.\n",
    "\n",
    "Next, depending on the dimension and number of hidden layers defined in the configuration these hidden layers get added as Dense layers.\n",
    "\n",
    "As a last step the output layer gets added. If the `discretize_actions` optimization is turned the number of chosen bins will be used to add an extra Dense layer. This Dense layer has an input shape of $\\text{num_bins} \\cdot \\text{adim}$ to enable the custom `DiscretizeActionsLayer` to reshape the input to $[-1, \\text{adim}, \\text{num_bins}]$. From there it pics the argument with the maximum value from the third dimension. This essentially means that it will pick `adim` maximum values from the bins. As a last step the picked values get transformed into the $[\\text{alow}, \\text{ahigh}]$ interval, which for the Roboschool environments is typically $[-1, 1]$.\n",
    "\n",
    "If `discretize_actions` optimization is not used a simple Dense Layer with the action dimension serves as output layer.\n",
    "\n",
    "All weights use the custom defined `Normc_initializer` to initialize their weights. This is copied from the OpenAI implementation, since initializing them differently can lead to a large minus reward when starting the training. With this custom layer one can specify the standard deviation for the random variables. For all layers `std=1.0` is used, except for the output layer and the layer before the `DiscretizeActionsLayer`, where `std=0.01` is set.\n",
    "A low standard deviation in the output layer leads to a more stable result.\n",
    "\n",
    "When `initial_weights` is provided these weights get set as the weights of the model. They need to be in the correct shape for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(initial_weights=None, model_name=\"model\", ob_mean=None, ob_std=None, model_file_path=None):\n",
    "       \n",
    "    import tensorflow as tf\n",
    "    \n",
    "    class Normc_initializer(tf.keras.initializers.Initializer):\n",
    "        def __init__(self, std=1.0):\n",
    "            self.std=std\n",
    "\n",
    "        def __call__(self, shape, dtype=None, partition_info=None):\n",
    "            out = np.random.randn(*shape).astype(np.float32)\n",
    "            out *= self.std / np.sqrt(np.square(out).sum(axis=0, keepdims=True))\n",
    "            return tf.constant(out)\n",
    "    \n",
    "    class ObservationNormalizationLayer(tf.keras.layers.Layer):\n",
    "        def __init__(self, ob_mean, ob_std, **kwargs):\n",
    "            self.ob_mean = ob_mean\n",
    "            self.ob_std = ob_std\n",
    "            super(ObservationNormalizationLayer, self).__init__(**kwargs)\n",
    "\n",
    "        def call(self, x):\n",
    "            return tf.clip_by_value((x - self.ob_mean) / self.ob_std, -5.0, 5.0)\n",
    "        \n",
    "        # get_config and from_config need to implemented to be able to serialize the model\n",
    "        def get_config(self):\n",
    "            base_config = super(ObservationNormalizationLayer, self).get_config()\n",
    "            base_config['ob_mean'] = self.ob_mean\n",
    "            base_config['ob_std'] = self.ob_std\n",
    "            return base_config\n",
    "        \n",
    "        @classmethod\n",
    "        def from_config(cls, config):\n",
    "            return cls(**config)\n",
    "        \n",
    "    class DiscretizeActionsUniformLayer(tf.keras.layers.Layer):\n",
    "        def __init__(self, num_ac_bins, adim, ahigh, alow, **kwargs):\n",
    "            self.num_ac_bins = num_ac_bins\n",
    "            self.adim = adim\n",
    "            # ahigh, alow are NumPy arrays when extracting from the environment, but when the model is loaded from a h5\n",
    "            # File they get initialised as a normal list, where operations like subtraction does not work, thereforce\n",
    "            # cast them explicitly\n",
    "            self.ahigh = np.array(ahigh)\n",
    "            self.alow = np.array(alow)\n",
    "            super(DiscretizeActionsUniformLayer, self).__init__(**kwargs)\n",
    "\n",
    "        def call(self, x):            \n",
    "            # Reshape to [n x i x j] where n is dynamically chosen, i equals action dimension and j equals the number\n",
    "            # of bins\n",
    "            scores_nab = tf.reshape(x, [-1, self.adim, self.num_ac_bins])\n",
    "            # This picks the bin with the greatest value\n",
    "            a = tf.argmax(scores_nab, 2)\n",
    "            \n",
    "            # Then transform the interval from [0, num_ac_bins - 1] to [-1, 1] which equals alow and ahigh\n",
    "            ac_range_1a = (self.ahigh - self.alow)[None, :]\n",
    "            return 1. / (self.num_ac_bins - 1.) * tf.keras.backend.cast(a, 'float32') * ac_range_1a + self.alow[None, :]        \n",
    "        \n",
    "        # get_config and from_config need to implemented to be able to serialize the model\n",
    "        def get_config(self):\n",
    "            base_config = super(DiscretizeActionsUniformLayer, self).get_config()\n",
    "            base_config['num_ac_bins'] = self.num_ac_bins\n",
    "            base_config['adim'] = self.adim\n",
    "            base_config['ahigh'] = self.ahigh\n",
    "            base_config['alow'] = self.alow\n",
    "            return base_config\n",
    "        \n",
    "        @classmethod\n",
    "        def from_config(cls, config):\n",
    "            return cls(**config)\n",
    "    \n",
    "    if model_file_path is not None:\n",
    "        custom_objects = {\n",
    "            \"Normc_initializer\" : Normc_initializer, \n",
    "            \"ObservationNormalizationLayer\" : ObservationNormalizationLayer,\n",
    "            \"DiscretizeActionsUniformLayer\" : DiscretizeActionsUniformLayer\n",
    "        }\n",
    "    \n",
    "        try:\n",
    "            model = tf.keras.models.load_model(model_file_path, custom_objects=custom_objects)\n",
    "        except IOError as e:\n",
    "            print(\"Could not load the model provided in {}\".format(model_file_path))\n",
    "        else:\n",
    "            return model\n",
    "    \n",
    "    ac_space = env.action_space\n",
    "    ob_space = env.observation_space\n",
    "    \n",
    "    nonlin = tf.nn.tanh\n",
    "    \n",
    "    if model_structure.nonlin_type == 'relu':\n",
    "        nonlin = tf.nn.relu\n",
    "    elif model_structure.nonlin_type == 'lrelu':\n",
    "        nonlin = tf.nn.leaky_relu\n",
    "    elif model_structure.nonlin_type == 'elu':\n",
    "        nonlin = tf.nn.leaky_relu\n",
    "\n",
    "    # Policy network\n",
    "    input_layer = x = tf.keras.Input(ob_space.shape, dtype=tf.float32)\n",
    "    \n",
    "    if ob_mean is not None and ob_std is not None and optimizations.observation_normalization:\n",
    "        if ob_std.all() != 0:\n",
    "            x = ObservationNormalizationLayer(ob_mean, ob_std)(x)\n",
    "                \n",
    "    for hd in model_structure.hidden_dims:\n",
    "        x = tf.keras.layers.Dense(\n",
    "            hd, activation=nonlin,\n",
    "            kernel_initializer=tf.random_normal_initializer(),#Normc_initializer(std=1.0),\n",
    "            bias_initializer=tf.initializers.zeros())(x)\n",
    "\n",
    "    # Action dimension and the lowest and highest possible values for an action\n",
    "    adim, ahigh, alow = ac_space.shape[0], ac_space.high, ac_space.low        \n",
    "    \n",
    "    if optimizations.discretize_actions:\n",
    "        num_ac_bins = int(model_structure.ac_bins)\n",
    "        x = tf.keras.layers.Dense(\n",
    "                        adim * num_ac_bins,\n",
    "                        kernel_initializer=tf.random_normal_initializer(),#Normc_initializer(std=0.01),\n",
    "                        bias_initializer=tf.initializers.zeros())(x)\n",
    "        a = DiscretizeActionsUniformLayer(num_ac_bins, adim, ahigh, alow)(x)\n",
    "    else:\n",
    "        a = tf.keras.layers.Dense(\n",
    "            adim,\n",
    "            kernel_initializer=tf.random_normal_initializer(),#Normc_initializer(std=0.01),\n",
    "            bias_initializer=tf.initializers.zeros())(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=a, name=model_name)\n",
    "    \n",
    "    if initial_weights is not None:\n",
    "        set_from_flat(model, initial_weights)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the act function\n",
    "\n",
    "The `act` function gets the current observation of an environment as parameter as well as the model which shalle be used to predict the action based on this observation. Therefore `act` gets called on every timestep in the `rollout` method which will be discussed in a bit. In addition if `random_stream` is provided, which is done by default in training, noise gets added to the predicted training to make the model more robust and generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def act(ob, model, random_stream=None):\n",
    "    time_predict_s = time.time()\n",
    "    action = model.predict_on_batch(ob)\n",
    "    time_predict_e = time.time() - time_predict_s\n",
    "\n",
    "    if random_stream is not None and model_structure.ac_noise_std != 0:\n",
    "        action += random_stream.randn(*action.shape) * model_structure.ac_noise_std\n",
    "    return action, time_predict_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The RunningStat class\n",
    "\n",
    "This class is used for tracking the observations during training. It is only used in combination with the `observation_normalization` optimization. When used, the master holds an object of this class and updates the `sum`, `sumsq` and `count` attributes with the values computed by the masters. Then when the master puts out a new task it provides the current `ob_mean` and `ob_std` with the two methods `mean` and `std` which will be provided to the workers.\n",
    "\n",
    "The workers simply track the observations by appending the observation for each step in the environment to a list, calculate the sums, add them to their own RunningStat object and send them to the master inside a `Result` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class RunningStat(object):\n",
    "    def __init__(self, shape, eps):\n",
    "        self.sum = np.zeros(shape, dtype=np.float32)\n",
    "        self.sumsq = np.full(shape, eps, dtype=np.float32)\n",
    "        self.count = eps\n",
    "        \n",
    "    def save(self, save_file):\n",
    "        # leading underscore in sum to distinct with 'sum' keyword\n",
    "        np.savez(save_file, _sum=self.sum, sumsq=self.sumsq, count=self.count)\n",
    "\n",
    "    def load(self, save_file):\n",
    "        self.data = None\n",
    "        try:\n",
    "            self.data = np.load(save_file, allow_pickle=True)\n",
    "        except IOError:\n",
    "            print(\"{} cannot be found or is not a file. Initializing observation normalization with default values.\".format(save_file))\n",
    "        except KeyError:\n",
    "            print(\"The file {} is corrupted or not created by this program. Initializing observation normalization with default values.\".format(save_file))\n",
    "        else:\n",
    "            try:\n",
    "                _sum = self.data[\"_sum\"]\n",
    "                sumsq = self.data[\"sumsq\"]\n",
    "                count = int(self.data[\"count\"])\n",
    "            except KeyError:\n",
    "                print(\"{} does not provide enough data to initialize the observation normalization. Using default values\".format(save_file))\n",
    "            except TypeError:\n",
    "                print(\"The data from {} does not match or is corrupted. Using default values\".format(save_file))\n",
    "            else:\n",
    "                self.sum = _sum\n",
    "                self.sumsq = sumsq\n",
    "                self.count = count\n",
    "        \n",
    "    def increment(self, s, ssq, c):\n",
    "        self.sum += s\n",
    "        self.sumsq += ssq\n",
    "        self.count += c\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        return self.sum / self.count\n",
    "\n",
    "    @property\n",
    "    def std(self):\n",
    "        return np.sqrt(np.maximum(self.sumsq / self.count - np.square(self.mean), 1e-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifiying the number of paramters\n",
    "\n",
    "For the Optimizer classes we need the total amount of parameters in our models. For this we define the `get_initial_weights` methods, which will create us a normal model, prints its layout and returns the random weights.\n",
    "Remember this needs to be done in a subprocess to avoid creating a TensorFlow session in the main process. So we call a `multiprocessing` `Pool` which allows us to spawn a subprocess and return the weights. In addition, the model structure is printed out.\n",
    "\n",
    "We then calculate the number of parameters from our weight vector $\\theta$. The weight vector is also important for later, because it will be the starting weight vector for our training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_initial_weights(ob_mean=None, ob_std=None, model_file_path=None):\n",
    "    \n",
    "    model = create_model(ob_mean=ob_mean, ob_std=ob_std, model_file_path=model_file_path)\n",
    "    \n",
    "    # Print out the model\n",
    "    model.summary()\n",
    "    \n",
    "    return model.get_weights()\n",
    "\n",
    "def initialize_parameter_vector(model_file_path=None):\n",
    "    with multiprocessing.Pool(1) as pool:\n",
    "        if optimizations.observation_normalization:\n",
    "            ob_stat = RunningStat(\n",
    "                env.observation_space.shape,\n",
    "                eps=1e-2  # eps to prevent dividing by zero at the beginning when computing mean/stdev\n",
    "                )\n",
    "            theta = pool.apply(func=get_initial_weights, args=(ob_stat.mean, ob_stat.std, model_file_path))\n",
    "        else:\n",
    "            theta = pool.apply(func=get_initial_weights, args=(None, None, model_file_path))\n",
    "\n",
    "    return theta, sum(np.prod(v.shape) for v in theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization: Using a neural network optimizer\n",
    "\n",
    "These optimizer are copied from the implementation from OpenAI. They are also implemented in Keras but need a loss function to work which we do not have when using neuroevolution.\n",
    "\n",
    "One must provide the `stepsize` attribute for both optimizers and can customize the other ones. It is recommended to leave them as is.\n",
    "\n",
    "Of course these classes do only get used when the `gradient_optimizer` optimization is active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Optimizer(object):\n",
    "    def __init__(self, num_params):\n",
    "        self.dim = num_params\n",
    "        self.t = 0\n",
    "        self.data = None\n",
    "        \n",
    "    def update(self, theta, globalg):\n",
    "        self.t += 1\n",
    "        step = self._compute_step(globalg)\n",
    "        ratio = np.linalg.norm(step) / np.linalg.norm(theta)\n",
    "        theta_new = theta + step\n",
    "        return theta_new, ratio\n",
    "\n",
    "    def save(self, save_file, **kwargs):\n",
    "        np.savez(save_file, **kwargs, t=self.t, dim=self.dim)\n",
    "        \n",
    "    def load(self, save_file):\n",
    "        self.data = None\n",
    "        try:\n",
    "            self.data = np.load(save_file, allow_pickle=True)\n",
    "        except IOError:\n",
    "            print(\"{} cannot be found or is not a file. Initializing optimizer with default values.\".format(save_file))\n",
    "        except KeyError:\n",
    "            print(\"The file {} is corrupted or not created by this program. Initializing the optimizer with default values.\".format(save_file))\n",
    "        else:\n",
    "            try:\n",
    "                t = int(self.data[\"t\"])\n",
    "                dim = int(self.data[\"dim\"])\n",
    "            except KeyError:\n",
    "                print(\"{} does not provide enough data to initialize the optimizer. Using default values\".format(save_file))\n",
    "            except TypeError:\n",
    "                print(\"The data from {} does not match or is corrupted. Using default values\".format(save_file))\n",
    "            else:\n",
    "                self.t = t\n",
    "                self.dim = dim\n",
    "\n",
    "    def _compute_step(self, globalg):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class SGD(Optimizer):\n",
    "    def __init__(self, num_params, stepsize, momentum=0.9):\n",
    "        Optimizer.__init__(self, num_params)\n",
    "        self.v = np.zeros(self.dim, dtype=np.float32)\n",
    "        self.stepsize, self.momentum = stepsize, momentum\n",
    "\n",
    "    def save(self, save_file, **kwargs):\n",
    "        super().save(save_file, stepsize=self.stepsize, momentum=self.momentum, v=self.v)\n",
    "        \n",
    "    def load(self, save_file):\n",
    "        super.load(save_file)\n",
    "        if self.data is not None:\n",
    "            try:\n",
    "                stepsize = float(self.data[\"stepsize\"])\n",
    "                momentum = float(self.data[\"momentum\"])\n",
    "                v = self.data[\"v\"]\n",
    "                assert isinstance(v, np.ndarray)\n",
    "                assert v.size == self.dim\n",
    "            except KeyError:\n",
    "                print(\"{} does not provide enough data to initialize the optimizer. Using default values\".format(save_file))\n",
    "            except TypeError or AssertionError:\n",
    "                # Either assertion error or cast failed. Same error message for both\n",
    "                print(\"The data from {} does not match or is corrupted. Using default values\".format(save_file))\n",
    "            else:\n",
    "                self.stepsize = stepsize\n",
    "                self.momentum = momentum\n",
    "                self.v = v\n",
    "    \n",
    "    def _compute_step(self, globalg):\n",
    "        self.v = self.momentum * self.v + (1. - self.momentum) * globalg\n",
    "        step = -self.stepsize * self.v\n",
    "        return step\n",
    "        \n",
    "class Adam(Optimizer):\n",
    "    def __init__(self, num_params, stepsize, beta1=0.9, beta2=0.999, epsilon=1e-08):\n",
    "        Optimizer.__init__(self, num_params)\n",
    "        self.stepsize = stepsize\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.m = np.zeros(self.dim, dtype=np.float32)\n",
    "        self.v = np.zeros(self.dim, dtype=np.float32)\n",
    "\n",
    "    def save(self, save_file, **kwargs):\n",
    "        super().save(save_file, stepsize=self.stepsize, beta1=self.beta1, beta2=self.beta2, epsilon=self.epsilon, m=self.m, v=self.v)\n",
    "        \n",
    "    def load(self, save_file):\n",
    "        super().load(save_file)\n",
    "        if self.data is not None:\n",
    "            try:\n",
    "                stepsize = float(self.data[\"stepsize\"])\n",
    "                beta1 = float(self.data[\"beta1\"])\n",
    "                beta2 = float(self.data[\"beta2\"])\n",
    "                epsilon = float(self.data[\"epsilon\"])\n",
    "                m = self.data[\"m\"]\n",
    "                v = self.data[\"v\"]\n",
    "                assert self.m.size == self.dim and self.v.size == self.dim\n",
    "                assert isinstance(m, np.ndarray)\n",
    "                assert isinstance(v, np.ndarray)\n",
    "            except KeyError:\n",
    "                print(\"{} does not provide enough data to initialize the optimizer. Using default values\".format(save_file))\n",
    "            except TypeError or AssertionError:\n",
    "                # Either assertion error or cast failed. Same error message for both\n",
    "                print(\"The data from {} does not match or is corrupted. Using default values\".format(save_file))\n",
    "            else:\n",
    "                self.stepsize = stepsize\n",
    "                self.beta1 = beta1\n",
    "                self.beta2 = beta2\n",
    "                self.epsilon = epsilon\n",
    "                self.m = m\n",
    "                self.v = v\n",
    "\n",
    "    def _compute_step(self, globalg):\n",
    "        a = self.stepsize * np.sqrt(1 - self.beta2 ** self.t) / (1 - self.beta1 ** self.t)\n",
    "        self.m = self.beta1 * self.m + (1 - self.beta1) * globalg\n",
    "        self.v = self.beta2 * self.v + (1 - self.beta2) * (globalg * globalg)\n",
    "        step = -a * self.m / (np.sqrt(self.v) + self.epsilon)\n",
    "        return step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Shared Noise\n",
    "\n",
    "To perturb the parameter vector we need noise to sample from. This class provides this noise to the master and the workers. It creates a multiprocessing array, which is stored in shared memory so every spawned process can access it. The array is then filled with samples from the standard normal distribution with the specified `seed`. As a default value `count` is set to $250 \\cdot 10^6$ which will sample 2GB of random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SharedNoiseTable(object):\n",
    "    def __init__(self, seed=123):\n",
    "        self.seed = seed\n",
    "        count = 250000000\n",
    "        print('Sampling {} random numbers with seed {}'.format(count, self.seed))\n",
    "\n",
    "        # Instantiate an array of C float datatype with size count\n",
    "        self._shared_mem = multiprocessing.Array(ctypes.c_float, count)\n",
    "\n",
    "        # Convert to numpy array\n",
    "        self.noise = np.ctypeslib.as_array(self._shared_mem.get_obj())\n",
    "        assert self.noise.dtype == np.float32\n",
    "        self.noise[:] = np.random.RandomState(seed).randn(count)\n",
    "        print('Sampled {} bytes'.format(self.noise.size * 4))\n",
    "\n",
    "    def get(self, i, dim):\n",
    "        return self.noise[i:i + dim]\n",
    "\n",
    "    def sample_index(self, stream, dim):\n",
    "        return stream.randint(0, len(self.noise) - dim + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Reshape the parameter vector\n",
    "\n",
    "Depending on our model structure the weight vector has a specific shape. To easily add or subtract noise, we define the `get_flat` and `set_from_flat` methods which will allow us to reshape the vector.\n",
    "\n",
    "`get_flat` as the name suggests flattens the given vector.\n",
    "\n",
    "`set_from_flat` serves two purposes. First it reshapes the one-dimensional array `theta` to the shape the model needs and then it sets the reshaped vector as the weight vector for the given `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_flat(theta):\n",
    "     return np.concatenate([np.reshape(v, [-1]) for v in theta], 0)\n",
    "\n",
    "def set_from_flat(model, theta):\n",
    "    old_theta = model.get_weights()\n",
    "    shapes = [v.shape for v in old_theta]\n",
    "    total_size = theta.size\n",
    "        \n",
    "    start = 0\n",
    "    reshapes = []\n",
    "    \n",
    "    for (shape, v) in zip(shapes, theta):\n",
    "        size = int(np.prod(shape))\n",
    "        reshapes.append(np.reshape(theta[start:start+size], shape))\n",
    "        start += size\n",
    "    \n",
    "    assert start == total_size\n",
    "    model.set_weights(reshapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### The rollout function\n",
    "\n",
    "This function will connect our model with our environment. Each environment in the OpenAI Gym has some functions with which it can be controlled. `env.reset()` resets the environment to the starting position and returns the initial observation. It must be called before doing anything else. `env.step(action)` does one timestep in the environment with the provided action vector and returns four values. First the observation, which represents the state of the environment after our action. Second, the reward for our action. Third, the boolean value `done` which is `True` when the environment reached a state where the environment is finished, for example after the maximum number of timesteps. The fourth value is `info` which gives additional information, but is not used here since for the two Roboschool environments `RoboschoolHumanoid-v1` and `RoboschoolAnt-v1`, `info` is just an empty set. Other than that the additional information would require a problem specific handling which we want to avoid when using black-box optimization.\n",
    "`env.render()` renders the environment and opens a window where one can see how the environment is performing instead of looking on only numbers. In training this is not done. When you want to view your progress you can use the additional Jupyter Notebook where you can load the latest model and visualize it.\n",
    "\n",
    "The way `rollout` works is that after resetting the environment and getting the first observation, it creates a loop for the maximum number of timesteps in the environment, mostly this is $1000$ timesteps. In this loop the act function is called with the observation `ob`, the model which is currently used and the perhabs provided `random_stream` which adds action noise to help generalize the model. Based on the model the action is predicted and returned which can then be used for a step in the environment. Lastly, the reward of this step gets saved to a list and the timestep counter `t` gets incremented. If the `save_obs` parameter is `True` every observation gets added to a list and returned later on to calculate the mean and standard deviation of the observation space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def rollout(env, \n",
    "            model, \n",
    "            *, \n",
    "            render=False, \n",
    "            timestep_limit=None, \n",
    "            save_obs=False, \n",
    "            random_stream=None):\n",
    "    \"\"\"\n",
    "    If random_stream is provided, the rollout will take noisy actions with noise drawn from that stream.\n",
    "    Otherwise, no action noise will be added.\n",
    "    \"\"\"\n",
    "    \n",
    "    env_timestep_limit = env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')\n",
    "    timestep_limit = env_timestep_limit if timestep_limit is None else min(timestep_limit, env_timestep_limit)\n",
    "    rews = []\n",
    "    times_predict = []\n",
    "    t = 0\n",
    "    if save_obs:\n",
    "        obs = []\n",
    "    ob = env.reset()\n",
    "    for _ in range(timestep_limit):\n",
    "        ac, time_predict = act(ob[None], model, random_stream=random_stream)\n",
    "        ac = ac[0]\n",
    "        times_predict.append(time_predict)\n",
    "        if save_obs:\n",
    "            obs.append(ob)\n",
    "        try:\n",
    "            ob, rew, done, _ = env.step(ac)\n",
    "        except AssertionError:\n",
    "            # Is thrown when for example ac is a list which has at least one entry with NaN\n",
    "            raise \n",
    "        rews.append(rew)\n",
    "        t += 1\n",
    "        if render:\n",
    "            env.render()\n",
    "        if done:\n",
    "            break\n",
    "    rews = np.array(rews, dtype=np.float32)\n",
    "    if save_obs:\n",
    "        return rews, t, np.array(obs), times_predict\n",
    "    return rews, t, times_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect the observations, if needed\n",
    "\n",
    "Now, we will define one last method before we go into how the workers operate. `rollout_and_update_ob_stat` is a helper function to do a rollout and collect the observation statistics. If the `observation_normalization` optimization is active, a random number is sampled. If this number is lower than `config.calc_obstat_prob` the rollout is started with the parameter `save_obs` set to `True`. This simply saves every observation after each step in the rollout and returns them as a NumPy array. The `task_ob_stat` then gets incremented with the values of this array. `task_ob_stat` is a RunningStat object created by the worker to keep track of the observation statistics. If the random number is greater or equal to `config.calc_obstat_prob` therew will be a standard rollout where the observations do not get collected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def rollout_and_update_ob_stat(env, model, rs, task_ob_stat):\n",
    "    if optimizations.observation_normalization and config.calc_obstat_prob != 0 and rs.rand() < config.calc_obstat_prob:\n",
    "        try:\n",
    "            rollout_rews, rollout_len, obs, times_predict = rollout(\n",
    "                env, model, save_obs=True, random_stream=rs)\n",
    "        except AssertionError:\n",
    "            raise\n",
    "        task_ob_stat.increment(obs.sum(axis=0), np.square(obs).sum(axis=0), len(obs))\n",
    "    else:\n",
    "        try:\n",
    "            rollout_rews, rollout_len, times_predict = rollout(env, model, random_stream=rs)\n",
    "        except AssertionError:\n",
    "            raise\n",
    "    return rollout_rews, rollout_len, times_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Using a master-worker architecture\n",
    "\n",
    "### The workers\n",
    "\n",
    "In the next cell we will define the `run_worker` method. As the name suggests this method will be executed by the worker processes. The way this works is that in the master a number of subprocesses is started using the `multiprocessing` package. Each subprocess will run the `run_worker` function with the given parameters `task_list`, `result_queue` and `num_params`. The workers get the latest task from the task list, compute it and push their result on the queue, where the master pulls the results from the queue as long as the configured population size did not exceed yet.\n",
    "\n",
    "In a more detailed manner, the worker function starts by importing `TensorFlow`, as well as `Keras`. Then the worker runs an infinite loop, where at the beginning the worker gets the last entry in the `task_list`. If a task with the same `task_id` is cached, the cached version will be used. If not the cache gets updated with the newest task and a new model is created. This is needed, since every new task has potentially a new observation mean and standard deviation and they need to be given when creating a model. An important step here is to know that Keras uses a TensorFlow session in the background for their computation. When one creates models in a loop this session gets filled up with new data which reduces the performance of a prediction, as well as it causes a memory leak. Therefore we need to call `clear_session` on the Keras backend which will destroy the current session and starts a new one. To improve performance we then need to set this new session to one with a defined configuration where we set `inter_op_parallelism_threads` and `intra_op_parallelism_threads` both to 1. These allow to use a Thread pool to compute TensorFlow operations, but since we already implemented parallel processing with our master-worker architectur adding another layer of multithreading just creates more overhead and hinders performance.\n",
    "Now the worker has the task and the model and can start computing. First it samples a random number. If this number is lower than `config.eval_prob` it will do an evaluation run. This simply takes the current parameter vector, which is `theta` in the task, and performs a rollout without adding noise. This gives insight into the different generations when starting the training. The result object will then consist of only `eval_return` which is the sum of the returned rewards, and `eval_length` which is the number of timesteps for this evaluation episode. Also `task_id` is added to the result for the master to check for outdated tasks (This will be explained when we get to the master).\n",
    "If the random number is greater or equal to `config.eval_prob`, the task will be calculated with noise. First, `task_ob_stat`, a RunningStat object is created to track the observations. Then we sample a noise vector from our SharedNoiseTable object `noise`, with dimension `num_params`. Then the weights of the model get updated with `set_from_flat` where define the new weigths as theta plus the noise vector. Then we call `rollout_and_update_ob_stat` which will do a rollout and potentially save the observations as previously discussed. If we also use `mirrored_sampling`, we set the weights to theta minus the noise vector and, again, do a rollout. We then send back the computation in a Result object which is pushed on the `result_queue`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_worker(task_list, result_queue, stop_work, noise, num_params):\n",
    "    from tensorflow.keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    # Threading pools set to 1 since we are parallelizing using multiprocessing\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "    \n",
    "    print(\"PID {}: Started worker\".format(os.getpid()))\n",
    "    \n",
    "    assert isinstance(noise, SharedNoiseTable)\n",
    "\n",
    "    # Setup\n",
    "    # Create a new gym environment object because each worker needs its own one\n",
    "    env = gym.make(config.env_id)\n",
    "        \n",
    "    # Random stream used for adding noise to the actions as well as deciding if the observation statistics shall be\n",
    "    # updated\n",
    "    rs = np.random.RandomState()\n",
    "    \n",
    "    wait_time = 1\n",
    "    \n",
    "    cached_task = None\n",
    "    cached_task_id = -1\n",
    "    model = None\n",
    "    \n",
    "    while not bool(stop_work.value):\n",
    "        # Get the latest Task from the Manger list\n",
    "        try:\n",
    "            task = task_list[-1]\n",
    "        except IndexError:\n",
    "            if wait_time > 100:\n",
    "                print(\"The task list does not get tasks, something went wrong in the Master. Aborting.\")\n",
    "                break\n",
    "            print(\"Task list is empty, waiting {} seconds before trying again\".format(wait_time))\n",
    "            wait_time *= 2\n",
    "            time.sleep(wait_time)\n",
    "            continue\n",
    "    \n",
    "        assert isinstance(task, Task)\n",
    "        task_id = task.task_id\n",
    "        assert isinstance(task_id, int)\n",
    "        \n",
    "        if task_id != cached_task_id:\n",
    "            cached_task = task\n",
    "            cached_task_id = task_id\n",
    "        \n",
    "            K.clear_session()\n",
    "            model = create_model(initial_weights=cached_task.theta, \n",
    "                             model_name=str(os.getpid()),\n",
    "                             ob_mean=cached_task.ob_mean,\n",
    "                             ob_std=cached_task.ob_std)\n",
    "        \n",
    "        if rs.rand() < config.eval_prob:\n",
    "            # Evaluation sample\n",
    "            set_from_flat(model, cached_task.theta)\n",
    "            try:\n",
    "                eval_rews, eval_length, times_predict = rollout(env, model)\n",
    "            except AssertionError:\n",
    "                result_queue.put(None)\n",
    "                return\n",
    "            \n",
    "            result_queue.put(Result(\n",
    "                noise_inds=None,\n",
    "                returns=None,\n",
    "                signreturns=None,\n",
    "                lengths=None,\n",
    "                eval_return=eval_rews.sum(),\n",
    "                eval_length=eval_length,\n",
    "                ob_sum=None,\n",
    "                ob_sumsq=None,\n",
    "                ob_count=None,\n",
    "                task_id=cached_task_id,\n",
    "                times_predict=times_predict\n",
    "            ))\n",
    "            \n",
    "        else:\n",
    "            task_ob_stat = RunningStat(env.observation_space.shape, eps=0.)  # eps=0 because we're incrementing only\n",
    "            \n",
    "            noise_inds, returns, signreturns, lengths = [], [], [], []\n",
    "            times_predict = []\n",
    "            \n",
    "            while not noise_inds:\n",
    "\n",
    "                # Noise sample\n",
    "                noise_idx = noise.sample_index(rs, num_params)\n",
    "                \n",
    "                epsilon = config.noise_stdev * noise.get(noise_idx, num_params)\n",
    "                \n",
    "                # Evaluate the sampled noise\n",
    "                set_from_flat(model, cached_task.theta + epsilon)\n",
    "                \n",
    "                try:\n",
    "                    rews_pos, len_pos, times_predict_pos = rollout_and_update_ob_stat(env,\n",
    "                                                                                      model,\n",
    "                                                                                      rs=rs,\n",
    "                                                                                      task_ob_stat=task_ob_stat)\n",
    "                except AssertionError:\n",
    "                    result_queue.put(None)\n",
    "                    return\n",
    "                \n",
    "                # Gather results\n",
    "                noise_inds.append(noise_idx)\n",
    "                returns.append([rews_pos.sum()])\n",
    "                signreturns.append([np.sign(rews_pos).sum()])\n",
    "                lengths.append([len_pos])\n",
    "                \n",
    "                times_predict += times_predict_pos\n",
    "\n",
    "                # Mirrored sampling also evaluates the noise by subtracting it\n",
    "                if optimizations.mirrored_sampling:\n",
    "                    set_from_flat(model, cached_task.theta - epsilon)\n",
    "                    \n",
    "                    try:\n",
    "                        rews_neg, len_neg, times_predict_neg = rollout_and_update_ob_stat(env,\n",
    "                                                                                          model, \n",
    "                                                                                          rs=rs, \n",
    "                                                                                          task_ob_stat=task_ob_stat)  \n",
    "                    except AssertionError:\n",
    "                        result_queue.put(None)\n",
    "                        return\n",
    "\n",
    "                    returns[-1].append(rews_neg.sum())\n",
    "                    signreturns[-1].append(np.sign(rews_neg).sum())\n",
    "                    lengths[-1].append(len_neg)\n",
    "                    \n",
    "                    times_predict += times_predict_neg\n",
    "\n",
    "            \n",
    "            result_queue.put(Result(\n",
    "                noise_inds=np.array(noise_inds),\n",
    "                returns=np.array(returns, dtype=np.float32),\n",
    "                signreturns=np.array(signreturns, dtype=np.float32),\n",
    "                lengths=np.array(lengths, dtype=np.int32),\n",
    "                eval_return=None,\n",
    "                eval_length=None,\n",
    "                ob_sum=None if task_ob_stat.count == 0 else task_ob_stat.sum,\n",
    "                ob_sumsq=None if task_ob_stat.count == 0 else task_ob_stat.sumsq,\n",
    "                ob_count=task_ob_stat.count,\n",
    "                task_id=cached_task_id,\n",
    "                times_predict=times_predict\n",
    "            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supporting functions for the master\n",
    "\n",
    "#### Batched dot product\n",
    "\n",
    "A computationally intense part of the algorithm is the calculation of this sum: $\\sum \\limits_{i=0}^n F_i \\epsilon_i$. It is the rewards, weighted by the used noise vector. For a large population, meaning a large $n$, this can get slow, but we use the following technique from the OpenAI implementation. The `weights` and `vecs` paramters get divided into smaller `groups` and then the dot product is calculated on these groups. Each grouped dot product is then simply summed which results in the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def itergroups(items, group_size):\n",
    "    assert group_size >= 1\n",
    "    group = []\n",
    "    for x in items:\n",
    "        group.append(x)\n",
    "        if len(group) == group_size:\n",
    "            yield tuple(group)\n",
    "            del group[:]\n",
    "    if group:\n",
    "        yield tuple(group)\n",
    "        \n",
    "def batched_weighted_sum(weights, vecs, batch_size):\n",
    "    total = 0.\n",
    "    num_items_summed = 0\n",
    "    for batch_weights, batch_vecs in zip(itergroups(weights, batch_size), itergroups(vecs, batch_size)):\n",
    "        assert len(batch_weights) == len(batch_vecs) <= batch_size\n",
    "        total += np.dot(np.asarray(batch_weights, dtype=np.float32), np.asarray(batch_vecs, dtype=np.float32))\n",
    "        num_items_summed += len(batch_weights)\n",
    "    return total, num_items_summed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization: Fitness shaping with a rank transformation\n",
    "\n",
    "One possible optimization which has not yet been discussed is rank transformation. What this does is, it transforms the range of rewards the master gets from the workers for a generation into ranks. So instead of having float numbers as rewards we get integer values in the $[0, len(x)]$ interval as our rewards. `compute_centered_ranks` therefore reshapes the paramter `x`, which in our case will be a one-dimensional reward array when no mirrored sampling is used and two-dimensional otherwise, and then invokes `compute_ranks` on it. This method sorts the input by the argument and sets the interval as the values. Back in the original method the returned array gets reshaped as it was and returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_ranks(x):\n",
    "    \"\"\"\n",
    "    Returns ranks in [0, len(x))\n",
    "    Note: This is different from scipy.stats.rankdata, which returns ranks in [1, len(x)].\n",
    "    \"\"\"\n",
    "    assert x.ndim == 1\n",
    "    ranks = np.empty(len(x), dtype=int)\n",
    "    ranks[x.argsort()] = np.arange(len(x))\n",
    "    return ranks\n",
    "\n",
    "\n",
    "def compute_centered_ranks(x):\n",
    "    y = compute_ranks(x.ravel()).reshape(x.shape).astype(np.float32)\n",
    "    y /= (x.size - 1)\n",
    "    y -= .5\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the function is called with a valid `save_path` the model gets saved to this path as a `.h5` file, including the current weights as well as the structure of the model. Normally, this allows to easily load the model based on the file without providing additional information. Here on the other hand, one must provide the custom classes `Normc_initializer`, `ObservationNormalizationLayer` and `DiscretizeActionsUniformLayer` when loading a saved model, since Keras does not have the implementation of these classes when the model gets loaded. An example and also visualizing the trained data can be found in the other Jupyter Notebook, called `evolution-strategies-visualize.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def save_model(save_directory, stop_work, save_tasks_queue):\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import backend as K\n",
    "    print(\"PID {}: Started saving process\".format(os.getpid()))\n",
    "    while not bool(stop_work.value):\n",
    "        save_task = save_tasks_queue.get()\n",
    "        assert isinstance(save_task, Task)\n",
    "        # We are creating models in a loop therefore we need to clear the session to avoid build up\n",
    "        K.clear_session()\n",
    "        model = create_model(initial_weights=save_task.theta, \n",
    "                            model_name=config.env_id + \"_Generation_\" + str(save_task.task_id),\n",
    "                            ob_mean=save_task.ob_mean,\n",
    "                            ob_std=save_task.ob_std)\n",
    "        \n",
    "        model.save(os.path.join(save_directory, \"snapshot_{:05d}.h5\".format(save_task.task_id)))\n",
    "        save_tasks_queue.task_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_training(init_from):\n",
    "    if init_from is not None:\n",
    "        assert isinstance(init_from, dict)\n",
    "        try:\n",
    "            save_dir = init_from[\"save_dir\"]\n",
    "            config_file = init_from[\"config\"]\n",
    "            log_file = init_from[\"log\"]\n",
    "            model_file = init_from[\"model_file\"]\n",
    "            optimizer_state_file = init_from[\"optimizer_state\"]\n",
    "            observation_norm_state_file = init_from[\"observation_norm_state\"]\n",
    "            assert os.path.isdir(save_dir)\n",
    "        except KeyError:\n",
    "            print(\"To resume training, init_from must contain 'config', 'model' and 'optimizer' keys.\")\n",
    "            return None, None, None\n",
    "        except AssertionError as e:\n",
    "            print(e)\n",
    "            print(\"Starting training from scratch.\")\n",
    "            return None, None, None\n",
    "        else:\n",
    "            if save_dir is None or config_file is None or model_file is None:\n",
    "                print(\"Please provide the config and model file you want to initialize the training from, as well as the directory they are stored in.\")\n",
    "                return None, None, None\n",
    "            # Config\n",
    "            with open(os.path.join(save_dir, config_file), encoding='utf-8') as f:\n",
    "                try:\n",
    "                    config_json = json.load(f)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(\"The config file {} is empty or cannot be parsed. Starting training from scratch.\".format(f))\n",
    "                else:\n",
    "                    # Does not catch false or missing values here!\n",
    "                    global optimizations, config, model_structure, env\n",
    "                    optimizations = Optimizations._make(config_json[\"optimizations\"].values())\n",
    "                    config = Config._make(config_json[\"config\"].values())\n",
    "                    model_structure = ModelStructure._make(config_json[\"model_structure\"].values())\n",
    "                    env = gym.make(config.env_id)                   \n",
    "\n",
    "            model_file_path = os.path.join(save_dir, model_file)\n",
    "            optimizer_state_file_path = None\n",
    "            observation_norm_state_file_path = None\n",
    "            \n",
    "            if optimizations.gradient_optimizer and optimizer_state_file is not None:\n",
    "                optimizer_state_file_path = os.path.join(save_dir, optimizer_state_file)\n",
    "                \n",
    "            if optimizations.observation_normalization and observation_norm_state_file_path is not None:\n",
    "                observation_norm_state_file_path = os.path.join(save_dir, observation_norm_state_file)\n",
    "                \n",
    "            return model_file_path, optimizer_state_file_path, observation_norm_state_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### The Master\n",
    "\n",
    "In the following cell the master and thus the training gets started. After the initial setup an infinite loop is started where in every iteration a new task, representing a new generation, gets pushed onto the task queue. The workers which have been started before the loop, pick up the new task and compute their results, which then, in turn, get enqueued onto the result queue. From their the master picks up results as long as the population size has not been exceeded. Then depending on the optimizations the results get processed and the parameter vector for the new generation is calculated. After logging the weights of the current model may get saved and then a new generation is started. This continues until one stops the kernel, or if you want you can change the infinite loop to a predefined length.\n",
    "\n",
    "#### Setup\n",
    "\n",
    "Preferably this notebook would be run in order and start the master cell one time to start the training. But since one may want to start the training again with different optimizations we need to create a subdirectory every time we start the training to avoid duplicating log and weight files.\n",
    "\n",
    "Note that if you alter the configuration files you of course need to restart that cell to _activate_ these settings. But the best way to restart a training is to restart the kernel and clear the output which resets this notebook. Remember that you sample a rather large noise object (approximately 1GB) of memory which resides does not get freed immediately after aborting the computation.\n",
    "\n",
    "After creating the noise object which is used by the master and all workers, we create the `task_list` as a list of a `Manager` object. The manager automatically shares the data between processes and handles access to it. For the `result_queue` we use a `multiprocessing.Queue` object. Like the list from the manger this queue object allows for access between processes but when one accesses an item of this queue with `get()` the item also gets removed from the queue. Each worker is a `multiprocessing.Process` which get the queue and list as parameter. Then they get started and compute in their infinite loop as previously discussed.\n",
    "\n",
    "If we use `observation_normalization` the `ob_stat` object is used to track the mean and standard deviation throughout the training. As a last setup step we define the headrow of our logging file which we save as a comma separated value file.\n",
    "\n",
    "#### Training\n",
    "\n",
    "The training starts by appending a new task to the task list. `theta` is the current parameter vector, which in the first generation is just the randomly initiated vector when creating a model. It is reshaped to be one-dimensional with the size `num_params` to easily add or subtract noise. After putting out the task we need to collect the results by the workers. In the while loop we iterate until `num_episodes_popped` exceed our configured population size. Inside the loop we first pop a result from the queue with `result_queue.get()`. This function blocks until an item is returned. Then we need to differentiate between two cases. First, the returned result is an evaluation result and second, the result is a job where noise was added. For the evaluation result we increase the `episodes_so_far` counter which counts exactly what its name says and add the timesteps of the evaluation to `timesteps_so_far`. Then we compare the `task_id` of the result and the task_id which is currently gathered by the master. If they match we have a valid evaluation for this task and we collect the reward of this evaluation and its timestep length to `eval_returns` and `eval_lengths`. For the second case we also increase `episodes_so_far` and `timesteps_so_far` depending on the number of episodes in the result object. Then again we compare the task id's. If they match, we append the result to the `curr_task_results` list and increase our `num_episodes_popped` counter, which remember is our exit condition for the while loop. If we use observation normalization we also increase the values in the `ob_stat` object. On the other hand if the task id's do not match we increase the `num_results_skipped` counter by one. Later on we can then calculate the fraction of skipped results.\n",
    "\n",
    "After the while loop whe have the results for this generation in `curr_task_results`. We then concatenate the noise indices, rewards and lengths of the results in `noise_inds`, `returns` and `lengths`. If we do fitness shaping we process the rewards with our method of computing the ranks. Then we calculate the dot product and divide by the number of episodes. If we use a gradient-based optimizer, like for example Adam, we input our gradient into it and get the updated `theta` back. Without an optimizer we devide by the standard deviation and multiply the learning rate, as described in the paper, to get our new parameter vector.\n",
    "\n",
    "Now we log the results of this generation to our csv file and if we snapshot the policy in this generation we create a model with our new theta as initial weights and store them to disk. This is done in a subprocess to avoid an inflicting TensorFlow session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_master(max_timesteps=np.inf, seed=123, init_from=None):\n",
    "    save_directory = os.path.join(main_directory, time.strftime('%d_%m_%Y-%Hh_%Mm_%Ss', time.localtime(time.time())))\n",
    "    mkdir_p(save_directory)\n",
    "    save_configuration(save_directory)\n",
    "\n",
    "    rs = np.random.RandomState()\n",
    "\n",
    "    noise = SharedNoiseTable(seed)\n",
    "    \n",
    "    model_file_path = None\n",
    "    optimizer_state_file_path = None\n",
    "    observation_norm_state_file_path = None\n",
    "    \n",
    "    if init_from is not None:\n",
    "        assert isinstance(init_from, dict)\n",
    "        print(\"Initializing training from previous state.\")\n",
    "        model_file_path, optimizer_state_file_path, observation_norm_state_file_path = resume_training(init_from)\n",
    "    \n",
    "    # Only used with observation_normalization optimization\n",
    "    ob_stat = RunningStat(\n",
    "        env.observation_space.shape,\n",
    "        eps=1e-2  # eps to prevent dividing by zero at the beginning when computing mean/stdev\n",
    "        )\n",
    "        \n",
    "    if optimizations.observation_normalization and observation_norm_state_file_path is not None:\n",
    "        ob_stat.load(observation_norm_state_file_path)\n",
    "    \n",
    "    theta, num_params = initialize_parameter_vector(model_file_path)\n",
    "    theta = get_flat(theta)\n",
    "\n",
    "    if optimizations.gradient_optimizer:\n",
    "        if model_structure.optimizer == OPTIMIZER_ADAM:\n",
    "            optimizer = Adam(int(num_params), **model_structure.optimizer_args)\n",
    "        elif model_structure.optimizer == OPTIMIZER_SGD:\n",
    "            optimizer = SGD(int(num_params), **model_structure.optimizer_args)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "            \n",
    "        if optimizer_state_file_path is not None:\n",
    "            # A previous state of the optimizer was given, restore it\n",
    "            optimizer.load(optimizer_state_file_path)\n",
    "            \n",
    "    '''    print(\"Optimizer stepsize {}\".format(optimizer.stepsize))\n",
    "    print(\"Optimizer t {}\".format(optimizer.t))\n",
    "    print(\"Optimizer v {}\".format(optimizer.v))\n",
    "    print(\"Optimizer m {}\".format(optimizer.m))'''\n",
    "    \n",
    "    manager = multiprocessing.Manager()\n",
    "    task_list = manager.list()\n",
    "    result_queue = multiprocessing.Queue()\n",
    "    save_tasks_queue = multiprocessing.JoinableQueue()\n",
    "    stop_work = multiprocessing.Value('i', 0, lock=False)\n",
    "\n",
    "    # Start workers\n",
    "    workers = []\n",
    "    for _ in range(config.num_workers):\n",
    "        worker = multiprocessing.Process(target=run_worker, args=(task_list, result_queue, stop_work, noise, num_params))\n",
    "        workers.append(worker)\n",
    "        worker.start()\n",
    "        \n",
    "    save_process = multiprocessing.Process(target=save_model, args=(save_directory, stop_work, save_tasks_queue))\n",
    "    save_process.start()\n",
    "\n",
    "    episodes_so_far = 0\n",
    "    timesteps_so_far = 0\n",
    "    generations = 0\n",
    "    tstart = time.time()\n",
    "\n",
    "\n",
    "\n",
    "    generation_log = OrderedDict()\n",
    "    generation_log_file = os.path.join(save_directory, 'log.csv')\n",
    "    fieldnames = [\n",
    "        'Generation',\n",
    "        'GenRewMean', 'GenRewStd', 'GenLenMean', \n",
    "        'EvalGenRewardMean', 'EvalGenRewardStd', 'EvalGenLengthMean', 'EvalGenCount',\n",
    "        'EpisodesThisGen', 'EpisodesSoFar', 'TimestepsThisGen', 'TimestepsSoFar',\n",
    "        'UniqueWorkers', 'ResultsSkippedFrac', 'ObCount',\n",
    "        'TimeElapsedThisGen', 'TimeElapsed',\n",
    "        'TimePredictMin', 'TimePredictMax', 'TimePredictMean', 'TimePredictCount']\n",
    "\n",
    "    with open(generation_log_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "    while timesteps_so_far < max_timesteps:\n",
    "        step_tstart = time.time()\n",
    "\n",
    "        task_list.append(Task(\n",
    "            theta=theta,\n",
    "            ob_mean=ob_stat.mean if optimizations.observation_normalization else None,\n",
    "            ob_std=ob_stat.std if optimizations.observation_normalization else None,\n",
    "            task_id=generations\n",
    "        ))\n",
    "\n",
    "        print(\"---------------- Generation: {}----------------\".format(generations))\n",
    "\n",
    "        assert theta.dtype == np.float32\n",
    "\n",
    "        curr_task_results, eval_returns, eval_lengths = [], [], []\n",
    "        num_results_skipped, num_episodes_popped, num_timesteps_popped, ob_count_this_gen = 0, 0, 0, 0\n",
    "\n",
    "        times_predict = []\n",
    "        \n",
    "        stop_training = False\n",
    "\n",
    "        print(\"PID {}: Waiting for results\".format(os.getpid()))\n",
    "\n",
    "        while num_episodes_popped < config.population_size or num_timesteps_popped < config.timesteps_per_gen:\n",
    "            result = result_queue.get()\n",
    "            \n",
    "            if result is None:\n",
    "                print(\"Stopping training. The model produced non finite numbers inside the action vector. Try a\"\n",
    "                      + \" different configuration.\")\n",
    "                stop_training = True\n",
    "                break\n",
    "            \n",
    "            assert isinstance(result, Result)\n",
    "            task_id = result.task_id\n",
    "            assert isinstance(task_id, int)\n",
    "\n",
    "            assert (result.eval_return is None) == (result.eval_length is None)\n",
    "\n",
    "            if result.eval_length is not None:\n",
    "                # The result was an evaluation job therefore do not collect the result only the evaluation\n",
    "                if task_id == generations:\n",
    "                    eval_returns.append(result.eval_return)\n",
    "                    eval_lengths.append(result.eval_length)\n",
    "                    times_predict += result.times_predict\n",
    "            else:\n",
    "                assert result.noise_inds.ndim == 1 and result.returns.dtype == np.float32\n",
    "\n",
    "                if optimizations.mirrored_sampling:\n",
    "                    assert result.returns.shape == result.lengths.shape == (len(result.noise_inds), 2)\n",
    "                else:\n",
    "                    assert result.returns.shape == result.lengths.shape == (len(result.noise_inds), 1)\n",
    "\n",
    "                if task_id == generations:\n",
    "                    curr_task_results.append(result)\n",
    "                                    \n",
    "                    # Update counts\n",
    "                    result_num_eps = result.lengths.size\n",
    "                    result_num_timesteps = result.lengths.sum()\n",
    "                    episodes_so_far += result_num_eps\n",
    "                    timesteps_so_far += result_num_timesteps\n",
    "                    \n",
    "                    num_episodes_popped += result_num_eps\n",
    "                    num_timesteps_popped += result_num_timesteps\n",
    "\n",
    "                    # Update observation stats if the optimization is used\n",
    "                    if optimizations.observation_normalization and result.ob_count > 0:\n",
    "                        ob_stat.increment(result.ob_sum, result.ob_sumsq, result.ob_count)\n",
    "                        ob_count_this_gen += result.ob_count\n",
    "                        \n",
    "                    times_predict += result.times_predict\n",
    "                else:\n",
    "                    num_results_skipped += 1\n",
    "\n",
    "        if stop_training:\n",
    "            break\n",
    "            \n",
    "        print(\"Gathered results\")\n",
    "\n",
    "        # Compute skip fraction\n",
    "        frac_results_skipped = num_results_skipped / (num_results_skipped + len(curr_task_results))\n",
    "        if num_results_skipped > 0:\n",
    "            print(\"Skipped {} out of date results ({:.2f}%)\".format(\n",
    "                num_results_skipped, 100. * frac_results_skipped))\n",
    "\n",
    "        # Assemble results\n",
    "        noise_inds = np.concatenate([r.noise_inds for r in curr_task_results])\n",
    "        returns = np.concatenate([r.returns for r in curr_task_results])\n",
    "        lengths = np.concatenate([r.lengths for r in curr_task_results])\n",
    "        assert noise_inds.shape[0] == returns.shape[0] == lengths.shape[0]\n",
    "\n",
    "        # If fitness shaping is turned on rank the results\n",
    "        if optimizations.fitness_shaping:\n",
    "            if config.return_proc_mode == RETURN_PROC_MODE_CR:\n",
    "                proc_returns = compute_centered_ranks(returns)\n",
    "            # sign and centered_sign_rank are obviously only useful in combination with mirrored sampling\n",
    "            elif config.return_proc_mode == RETURN_PROC_MODE_SIGN:\n",
    "                proc_returns = np.concatenate([r.signreturns for r in curr_task_results])\n",
    "            elif config.return_proc_mode == RETURN_PROC_MODE_CR_SIGN:\n",
    "                proc_returns = compute_centered_ranks(np.concatenate([r.signreturns for r in curr_task_results]))\n",
    "            else:\n",
    "                # Throw error to indicate the false input instead of silently pass on.\n",
    "                # This should have been already catched in the configuration section, so this here is a misconfiguration.\n",
    "                raise NotImplementedError\n",
    "        else:\n",
    "            proc_returns = returns\n",
    "\n",
    "        # Mirrored sampling returns a 2D numpy array therefore we need to preprocess it accordingly\n",
    "        if optimizations.mirrored_sampling:\n",
    "            # Calculates the difference between the rewards sampled with the positive and negative noise\n",
    "            proc_returns = proc_returns[:, 0] - proc_returns[:, 1]\n",
    "        else:\n",
    "            proc_returns = proc_returns.ravel()\n",
    "\n",
    "        # Calculate the approximated gradient with a batch variant which saves time on large vectors\n",
    "        g, count = batched_weighted_sum(\n",
    "            proc_returns,\n",
    "            (noise.get(idx, num_params) for idx in noise_inds),\n",
    "            batch_size=500\n",
    "        )\n",
    "\n",
    "        assert g.shape == (num_params,) and g.dtype == np.float32 and count == len(noise_inds)\n",
    "        \n",
    "        # Update with the approximated gradient\n",
    "        g /= returns.size\n",
    "        \n",
    "        if optimizations.divide_by_stdev:\n",
    "            g /= config.noise_stdev\n",
    "            \n",
    "        if optimizations.gradient_optimizer:\n",
    "            step = -g\n",
    "            if optimizations.weight_decay:\n",
    "                step += config.l2coeff * theta\n",
    "            theta, _ = optimizer.update(theta, step)\n",
    "        else:\n",
    "            step = g * config.learning_rate\n",
    "            if optimizations.weight_decay:\n",
    "                step *= config.l2coeff\n",
    "            theta += step\n",
    "        \n",
    "        step_tend = time.time()\n",
    "\n",
    "        # Log the generation and print to stdout\n",
    "        generation_log['Generation'] = generations\n",
    "\n",
    "        generation_log['GenRewMean'] = returns.mean()\n",
    "        generation_log['GenRewStd'] = returns.std()\n",
    "        generation_log['GenLenMean'] = lengths.mean()\n",
    "\n",
    "        generation_log['EvalGenRewardMean'] = np.nan if not eval_returns else np.mean(eval_returns)\n",
    "        generation_log['EvalGenRewardStd'] = np.nan if not eval_returns else np.std(eval_returns)\n",
    "        generation_log['EvalGenLengthMean'] = np.nan if not eval_lengths else np.mean(eval_lengths)\n",
    "        generation_log['EvalGenCount'] = len(eval_returns)\n",
    "\n",
    "        generation_log['EpisodesThisGen'] = lengths.size\n",
    "        generation_log['EpisodesSoFar'] = episodes_so_far\n",
    "        generation_log['TimestepsThisGen'] = lengths.sum()\n",
    "        generation_log['TimestepsSoFar'] = timesteps_so_far\n",
    "\n",
    "        generation_log['UniqueWorkers'] = config.num_workers\n",
    "        generation_log['ResultsSkippedFrac'] = frac_results_skipped\n",
    "        generation_log['ObCount'] = ob_count_this_gen\n",
    "\n",
    "        generation_log['TimeElapsedThisGen'] = step_tend - step_tstart\n",
    "        generation_log['TimeElapsed'] = step_tend - tstart\n",
    "\n",
    "        generation_log['TimePredictMin'] = np.amin(times_predict)\n",
    "        generation_log['TimePredictMax'] = np.amax(times_predict)\n",
    "        generation_log['TimePredictMean'] = np.mean(times_predict)\n",
    "        generation_log['TimePredictCount'] = len(times_predict)\n",
    "\n",
    "        for key, value in generation_log.items():\n",
    "            print(f'{key:25} {value}')\n",
    "\n",
    "        # Append the log the csv file\n",
    "        with open(generation_log_file, 'a', newline='') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writerow(generation_log)\n",
    "\n",
    "        # Note that the model is created with a custom layer and custom initializer, and therefore needs these two\n",
    "        # custom classes if one wants to load a saved model\n",
    "        if config.snapshot_freq != 0 and generations % config.snapshot_freq == 0:\n",
    "            \n",
    "            # Save model\n",
    "            save_tasks_queue.put(Task(\n",
    "                theta=theta,\n",
    "                ob_mean=ob_stat.mean if optimizations.observation_normalization else None,\n",
    "                ob_std=ob_stat.std if optimizations.observation_normalization else None,\n",
    "                task_id=generations\n",
    "                ))\n",
    "            \n",
    "            # Save optimizer\n",
    "            if optimizations.gradient_optimizer:\n",
    "                optimizer.save(os.path.join(save_directory, \"optimizer_{:05d}.npz\".format(generations)))\n",
    "                \n",
    "            # Save observation normalization\n",
    "            if optimizations.observation_normalization:\n",
    "                ob_stat.save(os.path.join(save_directory, \"ob_normalization_{:05d}.npz\".format(generations)))\n",
    "\n",
    "            print(\"Saved training state in generation {} to {}\".format(generations, save_directory))\n",
    "\n",
    "        generations += 1\n",
    "\n",
    "    # Quit the multiprocessing data structures and processes\n",
    "    stop_work.value = 1\n",
    "\n",
    "    result_queue.close()\n",
    "    \n",
    "    for w in workers:\n",
    "        # Workers are blocking on empty queues and cannot be joined. When attempted they will try to join forever\n",
    "        # Therefore we terminate the process. This is not crucial since we already saved everything for the last\n",
    "        # generation.\n",
    "        w.terminate()\n",
    "        \n",
    "    # Save tasks queue is a joinable queue, therefore we can gracefully join the queue\n",
    "    save_tasks_queue.join()\n",
    "    save_tasks_queue.close()\n",
    "\n",
    "    # Like the worker processes a join would result in an indefinite block, since save_tasks_queue is closed and all\n",
    "    # save jobs have been processed we can terminate the process\n",
    "    save_process.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_from = {\n",
    "    \"save_dir\": \"/home/jovyan/work/evolution-strategies/training_runs/\",\n",
    "    \"config\": \"config.json\",\n",
    "    \"log\": None,\n",
    "    \"model_file\": \"snapshot_00003.h5\",\n",
    "    \"optimizer_state\": \"optimizer_00003.h5.npz\",\n",
    "    \"observation_norm_state\": \"ob_normalization00003.h5.npz\",                \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 250000000 random numbers with seed 123\n",
      "Sampled 1000000000 bytes\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28)]              0         \n",
      "_________________________________________________________________\n",
      "observation_normalization_la (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               7424      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 40)                10280     \n",
      "_________________________________________________________________\n",
      "discretize_actions_uniform_l (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 83,496\n",
      "Trainable params: 83,496\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "---------------- Generation: 0----------------\n",
      "PID 171: Waiting for results\n",
      "PID 287: Started worker\n",
      "PID 289: Started worker\n",
      "PID 285: Started worker\n",
      "PID 293: Started saving process\n",
      "PID 283: Started worker\n",
      "PID 292: Started worker\n",
      "PID 291: Started worker\n",
      "PID 279: Started worker\n",
      "PID 281: Started worker\n",
      "Gathered results\n",
      "Generation                0\n",
      "GenRewMean                -300.56793212890625\n",
      "GenRewStd                 153.18389892578125\n",
      "GenLenMean                1000.0\n",
      "EvalGenRewardMean         nan\n",
      "EvalGenRewardStd          nan\n",
      "EvalGenLengthMean         nan\n",
      "EvalGenCount              0\n",
      "EpisodesThisGen           10\n",
      "EpisodesSoFar             10\n",
      "TimestepsThisGen          10000\n",
      "TimestepsSoFar            10000\n",
      "UniqueWorkers             8\n",
      "ResultsSkippedFrac        0.0\n",
      "ObCount                   0\n",
      "TimeElapsedThisGen        11.408277034759521\n",
      "TimeElapsed               11.40914535522461\n",
      "TimePredictMin            0.0005447864532470703\n",
      "TimePredictMax            0.05135059356689453\n",
      "TimePredictMean           0.0013868007183074952\n",
      "TimePredictCount          10000\n",
      "Saved training state in generation 0 to /home/jovyan/work/evolution-strategies/training_runs/17_12_2019-15h_40m_12s\n",
      "---------------- Generation: 1----------------\n",
      "PID 171: Waiting for results\n",
      "Gathered results\n",
      "Skipped 10 out of date results (66.67%)\n",
      "Generation                1\n",
      "GenRewMean                -252.72274780273438\n",
      "GenRewStd                 113.17203521728516\n",
      "GenLenMean                1000.0\n",
      "EvalGenRewardMean         nan\n",
      "EvalGenRewardStd          nan\n",
      "EvalGenLengthMean         nan\n",
      "EvalGenCount              0\n",
      "EpisodesThisGen           10\n",
      "EpisodesSoFar             20\n",
      "TimestepsThisGen          10000\n",
      "TimestepsSoFar            20000\n",
      "UniqueWorkers             8\n",
      "ResultsSkippedFrac        0.6666666666666666\n",
      "ObCount                   0\n",
      "TimeElapsedThisGen        10.838772296905518\n",
      "TimeElapsed               22.292449474334717\n",
      "TimePredictMin            0.0005085468292236328\n",
      "TimePredictMax            0.03929901123046875\n",
      "TimePredictMean           0.001045456600189209\n",
      "TimePredictCount          10000\n",
      "Saved training state in generation 1 to /home/jovyan/work/evolution-strategies/training_runs/17_12_2019-15h_40m_12s\n",
      "---------------- Generation: 2----------------\n",
      "PID 171: Waiting for results\n",
      "Gathered results\n",
      "Skipped 9 out of date results (64.29%)\n",
      "Generation                2\n",
      "GenRewMean                -188.4812469482422\n",
      "GenRewStd                 227.80624389648438\n",
      "GenLenMean                1000.0\n",
      "EvalGenRewardMean         nan\n",
      "EvalGenRewardStd          nan\n",
      "EvalGenLengthMean         nan\n",
      "EvalGenCount              0\n",
      "EpisodesThisGen           10\n",
      "EpisodesSoFar             30\n",
      "TimestepsThisGen          10000\n",
      "TimestepsSoFar            30000\n",
      "UniqueWorkers             8\n",
      "ResultsSkippedFrac        0.6428571428571429\n",
      "ObCount                   0\n",
      "TimeElapsedThisGen        10.027251482009888\n",
      "TimeElapsed               32.418479681015015\n",
      "TimePredictMin            0.0005433559417724609\n",
      "TimePredictMax            0.031124114990234375\n",
      "TimePredictMean           0.000984059476852417\n",
      "TimePredictCount          10000\n",
      "Saved training state in generation 2 to /home/jovyan/work/evolution-strategies/training_runs/17_12_2019-15h_40m_12s\n",
      "---------------- Generation: 3----------------\n",
      "PID 171: Waiting for results\n",
      "Gathered results\n",
      "Skipped 8 out of date results (61.54%)\n",
      "Generation                3\n",
      "GenRewMean                -257.2778625488281\n",
      "GenRewStd                 159.76255798339844\n",
      "GenLenMean                1000.0\n",
      "EvalGenRewardMean         nan\n",
      "EvalGenRewardStd          nan\n",
      "EvalGenLengthMean         nan\n",
      "EvalGenCount              0\n",
      "EpisodesThisGen           10\n",
      "EpisodesSoFar             40\n",
      "TimestepsThisGen          10000\n",
      "TimestepsSoFar            40000\n",
      "UniqueWorkers             8\n",
      "ResultsSkippedFrac        0.6153846153846154\n",
      "ObCount                   0\n",
      "TimeElapsedThisGen        6.205073118209839\n",
      "TimeElapsed               38.67924785614014\n",
      "TimePredictMin            0.0005476474761962891\n",
      "TimePredictMax            0.046946048736572266\n",
      "TimePredictMean           0.0010572166681289672\n",
      "TimePredictCount          10000\n",
      "Saved training state in generation 3 to /home/jovyan/work/evolution-strategies/training_runs/17_12_2019-15h_40m_12s\n"
     ]
    }
   ],
   "source": [
    "run_master(seed=123, max_timesteps=40e3, init_from=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
